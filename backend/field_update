#!/usr/bin/env python3
# Copyright (C) 2021 Humanitarian OpenStreetmap Team

# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.

# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

# Humanitarian OpenStreetmap Team
# 1100 13th Street NW Suite 800 Washington, D.C. 20005
# <info@hotosm.org>


import argparse
import asyncio
import logging
import os
from enum import Enum

import asyncpg
from cpuinfo import get_cpu_info
from dateutil.relativedelta import relativedelta
from tqdm.asyncio import tqdm

logging.basicConfig(format="%(asctime)s - %(message)s", level=logging.DEBUG)

info = get_cpu_info()
cores = info["count"] * 2


class BatchFrequency(Enum):
    HOURLY = "h"
    DAILY = "d"
    WEEKLY = "w"
    MONTHLY = "m"
    QUARTERLY = "q"
    YEARLY = "y"


def assign_end_wrt_frequency(start, frequency):
    if frequency == BatchFrequency.HOURLY:
        return start - relativedelta(hours=1)
    elif frequency == BatchFrequency.DAILY:
        return start - relativedelta(days=1)
    elif frequency == BatchFrequency.WEEKLY:
        return start - relativedelta(weeks=1)
    elif frequency == BatchFrequency.MONTHLY:
        return start - relativedelta(months=1)
    elif frequency == BatchFrequency.QUARTERLY:
        return start - relativedelta(months=3)
    elif frequency == BatchFrequency.YEARLY:
        return start - relativedelta(years=1)


async def create_pool():
    return await asyncpg.create_pool(
        host=os.getenv("PGHOST", "localhost"),
        port=os.getenv("PGPORT", "5432"),
        user=os.getenv("PGUSER", "user"),
        password=os.getenv("PGPASSWORD", "password"),
        database=os.getenv("PGDATABASE", "database"),
    )


async def get_max_timestamp(conn, table):
    query = f"""SELECT MIN("timestamp") AS minimum, MAX("timestamp") AS maximum FROM {table};"""
    record = await conn.fetch(query)
    logging.debug(
        f"Maximum {table} timestamp fetched is {record[0]['maximum']} and minimum is {record[0]['minimum']}"
    )
    return record[0]["maximum"], record[0]["minimum"]


async def update_field(
    pool,
    start,
    end,
    target_table,
    target_column,
    target_geom,
    source_table,
    source_column,
    source_geom,
):
    query = f"""WITH 
    t1 AS (
        SELECT 
            osm_id,
            ST_Centroid({target_geom}) AS geom
        FROM 
            {target_table}
        WHERE 
            timestamp BETWEEN '{start}'::timestamp AND '{end}'::timestamp
    ),
    t2 AS (
        SELECT 
            t1.osm_id,
            CASE 
                WHEN COUNT(cg.{source_column}) = 0 THEN ARRAY[0]::integer[]
                ELSE array_agg(COALESCE(cg.{source_column}, 0))
            END AS aa_fids
        FROM 
            t1
        LEFT JOIN 
            {source_table} cg ON ST_Intersects(t1.geom, cg.{source_geom})
        GROUP BY 
            t1.osm_id
    )
    UPDATE 
        {target_table} uw
    SET 
        {target_column} = t2.aa_fids
    FROM 
        t2
    WHERE 
        t2.osm_id = uw.osm_id;"""
    async with pool.acquire() as conn:
        await conn.execute(query)


async def batch_update_parallel(
    start_batch_date,
    end_batch_date,
    batch_frequency,
    target_table,
    target_column,
    target_geom,
    source_table,
    source_column,
    source_geom,
    max_workers=cores,  # Number of threads
):
    pool = await create_pool()
    if start_batch_date is None or end_batch_date is None:
        async with pool.acquire() as conn:
            start_batch_date, end_batch_date = await get_max_timestamp(
                conn, target_table
            )

    logging.debug(
        f"Starting parallel batch update from {start_batch_date} to {end_batch_date} with frequency {batch_frequency}"
    )

    semaphore = asyncio.Semaphore(max_workers)

    async def bound_update_field(*args):
        async with semaphore:
            await update_field(pool, *args)

    tasks = []
    pbar = tqdm()
    try:
        while start_batch_date >= end_batch_date:
            end_date = assign_end_wrt_frequency(start_batch_date, batch_frequency)
            tasks.append(
                bound_update_field(
                    end_date,
                    start_batch_date,
                    target_table,
                    target_column,
                    target_geom,
                    source_table,
                    source_column,
                    source_geom,
                )
            )
            start_batch_date = end_date
            pbar.update(1)
        await asyncio.gather(*tasks)
    except Exception as e:
        logging.error(
            f"An error occurred during the parallel batch update process: {e}"
        )
        raise
    finally:
        pbar.close()
        await pool.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Batch update script")
    parser.add_argument("--start", help="Start date for batch update", required=False)
    parser.add_argument("--end", help="End date for batch update", required=False)
    parser.add_argument(
        "--freq",
        help="Frequency of batch updates",
        choices=[e.value for e in BatchFrequency],
        required=True,
    )
    parser.add_argument("--target_table", help="Target table to update", required=True)
    parser.add_argument(
        "--target_column", help="Target column to update", required=True
    )
    parser.add_argument("--target_geom", help="Target geometry column", required=True)
    parser.add_argument(
        "--source_table", help="Source table for update values", required=True
    )
    parser.add_argument(
        "--source_column", help="Source column for update values", required=True
    )
    parser.add_argument("--source_geom", help="Source geometry column", required=True)
    args = parser.parse_args()

    asyncio.run(
        batch_update_parallel(
            args.start,
            args.end,
            BatchFrequency(args.freq),
            args.target_table,
            args.target_column,
            args.target_geom,
            args.source_table,
            args.source_column,
            args.source_geom,
        )
    )
